"""
GPT Service
X·ª≠ l√Ω classification s·ª≠ d·ª•ng OpenAI GPT models
"""

import os
import json
import re
import asyncio
import logging
from typing import List, Dict, Optional
from dotenv import load_dotenv
import openai

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
base_url = os.getenv("OPENAI_API_BASE_URL")
model_name = os.getenv("MODEL_NAME", "gpt-5")

# Kh·ªüi t·∫°o OpenAI client
client = openai.OpenAI(base_url=base_url, api_key=api_key)


class GPTService:
    """Service ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi GPT models"""
    
    def __init__(self):
        self.client = client
        self.model_name = model_name
        logger.debug(f"GPT Service initialized with model: {model_name}")
    
    async def _call_model_with_retries(
        self, call_kwargs: dict, retries: int = 3, backoff_factor: float = 0.5
    ):
        """G·ªçi LLM v·ªõi retry logic v√† exponential backoff"""
        last_exc = None
        for attempt in range(1, retries + 1):
            try:
                resp = await asyncio.to_thread(
                    self.client.chat.completions.create, **call_kwargs
                )
                return resp
            except Exception as e:
                last_exc = e
                wait = backoff_factor * (2 ** (attempt - 1))
                logger.warning(f"‚ö†Ô∏è Attempt {attempt} failed, retrying in {wait}s...")
                await asyncio.sleep(wait)
        raise last_exc
    
    async def classify_bug(
        self, 
        description: str, 
        labels: List[str],
        label_descriptions: str,
        example_text: str,
        team_groups: List[str]
    ) -> Dict:
        logger.info("\n" + "="*80)
        logger.info("ü§ñ GPT CLASSIFY_BUG")
        logger.info(f"üìù Input: {description[:100]}..." if len(description) > 100 else f"üìù Input: {description}")
        
        # Build prompt
        prompt = f"""
=== VAI TR√í ===
B·∫°n l√† chuy√™n gia QA v·ªõi 10+ nƒÉm kinh nghi·ªám, chuy√™n ph√¢n t√≠ch v√† ph√¢n lo·∫°i bug cho c√°c h·ªá th·ªëng ph·∫ßn m·ªÅm l·ªõn.

=== NHI·ªÜM V·ª§ ===
Ph√¢n lo·∫°i b√°o c√°o bug d∆∞·ªõi ƒë√¢y v√†o CH√çNH X√ÅC M·ªòT nh√£n ph√π h·ª£p nh·∫•t t·ª´ danh s√°ch cho tr∆∞·ªõc.
ƒê√°nh gi√° m·ª©c ƒë·ªô nghi√™m tr·ªçng (severity) v√† x√°c ƒë·ªãnh team ch·ªãu tr√°ch nhi·ªám.

=== NG·ªÆ C·∫¢NH ===
C√°c nh√£n ph√¢n lo·∫°i c√≥ s·∫µn:
{label_descriptions}

C√°c v√≠ d·ª• minh h·ªça:
{example_text}

=== L·∫¨P LU·∫¨N ===
1. ƒê·ªçc to√†n b·ªô th√¥ng tin bug (c√≥ th·ªÉ ch·ª©a nhi·ªÅu tr∆∞·ªùng: No, Summary, Description, Priority, Status, v.v.).
2. T·ª∞ ƒê·ªòNG X√ÅC ƒê·ªäNH tr∆∞·ªùng n√†o ch·ª©a n·ªôi dung m√¥ t·∫£ bug ch√≠nh (th∆∞·ªùng l√† Summary, Description, ho·∫∑c c√°c tr∆∞·ªùng t∆∞∆°ng t·ª±).
3. B·ªé QUA c√°c th√¥ng tin kh√¥ng li√™n quan (nh∆∞ ID, Create date, Reporter, v.v.).
4. T·∫≠p trung v√†o n·ªôi dung m√¥ t·∫£ l·ªói ƒë·ªÉ x√°c ƒë·ªãnh t·ª´ kh√≥a ch√≠nh (keywords).
5. So s√°nh v·ªõi c√°c nh√£n c√≥ s·∫µn, t√¨m nh√£n kh·ªõp nh·∫•t v·ªÅ m·∫∑t ng·ªØ nghƒ©a.
6. N·∫øu c√≥ nhi·ªÅu nh√£n ph√π h·ª£p, ∆∞u ti√™n nh√£n c·ª• th·ªÉ h∆°n (VD: "Backend" > "Functional").
7. ƒê√°nh gi√° t√°c ƒë·ªông: Critical (h·ªá th·ªëng s·∫≠p/b·∫£o m·∫≠t) > High (ch·ª©c nƒÉng ch√≠nh l·ªói) > Medium (tr·∫£i nghi·ªám k√©m) > Low (hi·ªÉn th·ªã sai nh·ªè).

=== QUY T·∫ÆC ===
- KH√îNG b·ªãa ra nh√£n m·ªõi ngo√†i danh s√°ch.
- L√Ω do ph·∫£i ng·∫Øn g·ªçn (< 30 t·ª´) v√† b·∫±ng ti·∫øng Vi·ªát.
- Ph·∫£i ch·ªçn ƒë√∫ng team d·ª±a tr√™n nh√£n ph√¢n lo·∫°i.
- T·ª∞ ƒê·ªòNG l·ªçc th√¥ng tin quan tr·ªçng t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o.

Th√¥ng tin bug c·∫ßn ph√¢n lo·∫°i (c√≥ th·ªÉ ch·ª©a nhi·ªÅu tr∆∞·ªùng, h√£y t·ª± ƒë·ªông l·ªçc th√¥ng tin quan tr·ªçng):
<<<
{description}
>>>
        """
        
        # Function definition cho structured output
        classify_function = {
            "name": "classify_bug_report",
            "description": "Ph√¢n lo·∫°i bug report v√†o m·ªôt trong c√°c nh√£n ƒë·ªãnh s·∫µn",
            "parameters": {
                "type": "object",
                "properties": {
                    "label": {
                        "type": "string",
                        "enum": labels,
                        "description": "Nh√£n ph√¢n lo·∫°i bug",
                    },
                    "reason": {
                        "type": "string",
                        "description": "L√Ω do ph√¢n lo·∫°i (ng·∫Øn g·ªçn, < 30 t·ª´, ti·∫øng Vi·ªát)",
                    },
                    "team": {
                        "type": "string",
                        "enum": team_groups,
                        "description": "Team ch·ªãu tr√°ch nhi·ªám",
                    },
                    "severity": {
                        "type": "string",
                        "enum": ["Low", "Medium", "High", "Critical"],
                        "description": "M·ª©c ƒë·ªô nghi√™m tr·ªçng",
                    },
                },
                "required": ["label", "reason"],
            },
        }
        
        call_kwargs = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "You are a senior QA expert with 10+ years of experience. Follow the structured prompt precisely and output only valid JSON.",
                },
                {"role": "user", "content": prompt},
            ],
            "functions": [classify_function],
            "function_call": {"name": "classify_bug_report"},
            "max_tokens": 1500,
        }
        if not self.model_name.startswith("gpt-5"):
            call_kwargs["temperature"] = 0.0
        
        response = await self._call_model_with_retries(call_kwargs)
        
        # Extract function call result
        message = response.choices[0].message
        if message.function_call:
            try:
                args = json.loads(message.function_call.arguments)
                
                result = {
                    "label": args.get("label"),
                    "reason": (args.get("reason") or "").strip(),
                    "team": args.get("team"),
                    "severity": args.get("severity"),
                }
                logger.info(f"‚úÖ {result['label']} - {result.get('team', 'N/A')}")
                return result
            except Exception as e:
                logger.error(f"‚ùå Function call parse error: {e}")
        
        # Fallback: parse content as JSON
        raw = message.content
        if raw:
            try:
                parsed = json.loads(raw.strip())
                label = parsed.get("label")
                reason = parsed.get("reason") or ""
                team = parsed.get("team")
                severity = parsed.get("severity")
                
                if label and label in labels:
                    result = {
                        "label": label,
                        "reason": reason.strip(),
                        "team": team,
                        "severity": severity
                    }
                    logger.info(f"‚úÖ {label} (fallback)")
                    return result
            except Exception as e:
                logger.error(f"‚ùå JSON parse error: {e}")
            
            # Final fallback: regex search
            m = re.search(
                r"\b({})\b".format("|".join(re.escape(k) for k in labels)), raw
            )
            if m:
                result = {"label": m.group(1), "reason": raw, "team": None, "severity": None}
                logger.warning(f"‚ö†Ô∏è Regex fallback result: {result}")
                logger.info("="*80 + "\n")
                return result
        
        logger.error("‚ùå Classification failed")
        logger.info("="*80 + "\n")
        return {"label": "", "reason": "classification_failed", "team": None, "severity": None}
    
    async def batch_classify(
        self,
        descriptions: List[str],
        indexes: List[int],
        labels: List[str],
        label_descriptions: str,
        example_text: str,
        team_groups: List[str]
    ) -> Dict[int, Dict]:
        """
        Ph√¢n lo·∫°i nhi·ªÅu bug reports c√πng l√∫c s·ª≠ d·ª•ng GPT
        
        Args:
            descriptions: List c√°c m√¥ t·∫£ bug
            indexes: List c√°c index t∆∞∆°ng ·ª©ng
            labels: Danh s√°ch c√°c nh√£n c√≥ th·ªÉ
            label_descriptions: M√¥ t·∫£ chi ti·∫øt c√°c nh√£n
            example_text: C√°c v√≠ d·ª• few-shot
            team_groups: Danh s√°ch c√°c team
        
        Returns:
            Dict mapping index -> classification result
        """
        logger.info("\n" + "="*80)
        logger.info(f"ü§ñ GPT BATCH_CLASSIFY - Count: {len(descriptions)}")
        
        # Build batch prompt
        input_list_text = "\n".join(
            [f"[{idx}]: {descriptions[i]}" for i, idx in enumerate(indexes)]
        )
        
        batch_prompt = f"""
=== VAI TR√í ===
B·∫°n l√† chuy√™n gia QA v·ªõi 10+ nƒÉm kinh nghi·ªám, chuy√™n ph√¢n t√≠ch v√† ph√¢n lo·∫°i bug h√†ng lo·∫°t v·ªõi ƒë·ªô ch√≠nh x√°c cao.

=== NHI·ªÜM V·ª§ ===
Ph√¢n lo·∫°i T·∫§T C·∫¢ c√°c b√°o c√°o bug trong danh s√°ch d∆∞·ªõi ƒë√¢y.
M·ªói bug ph·∫£i ƒë∆∞·ª£c g√°n ƒê√öNG M·ªòT nh√£n, k√®m l√Ω do, team, v√† severity.

=== NG·ªÆ C·∫¢NH ===
C√°c nh√£n ph√¢n lo·∫°i c√≥ s·∫µn:
{label_descriptions}

C√°c v√≠ d·ª• minh h·ªça:
{example_text}

=== L·∫¨P LU·∫¨N ===
V·ªõi m·ªói bug:
1. ƒê·ªçc to√†n b·ªô th√¥ng tin (c√≥ th·ªÉ ch·ª©a nhi·ªÅu tr∆∞·ªùng nh∆∞ No, Summary, Description, Priority, v.v.).
2. T·ª∞ ƒê·ªòNG X√ÅC ƒê·ªäNH tr∆∞·ªùng n√†o ch·ª©a n·ªôi dung m√¥ t·∫£ bug ch√≠nh.
3. B·ªé QUA c√°c th√¥ng tin kh√¥ng li√™n quan (ID, ng√†y t·∫°o, ng∆∞·ªùi b√°o c√°o, v.v.).
4. X√°c ƒë·ªãnh t·ª´ kh√≥a ch√≠nh (keywords) t·ª´ n·ªôi dung m√¥ t·∫£ l·ªói.
5. So kh·ªõp v·ªõi danh s√°ch nh√£n, ch·ªçn nh√£n ph√π h·ª£p nh·∫•t.
6. ∆Øu ti√™n nh√£n c·ª• th·ªÉ (VD: "Database" > "Backend" n·∫øu li√™n quan query).
7. ƒê√°nh gi√° severity d·ª±a tr√™n t√°c ƒë·ªông th·ª±c t·∫ø.

=== QUY T·∫ÆC ===
- PH·∫¢I ph√¢n lo·∫°i h·∫øt t·∫•t c·∫£ c√°c bug (bao g·ªìm c·∫£ index trong danh s√°ch).
- KH√îNG b·ªè s√≥t bug n√†o.
- KH√îNG b·ªãa ra nh√£n m·ªõi ngo√†i danh s√°ch.
- L√Ω do ph·∫£i ng·∫Øn g·ªçn (< 30 t·ª´) v√† b·∫±ng ti·∫øng Vi·ªát.
- T·ª∞ ƒê·ªòNG l·ªçc th√¥ng tin quan tr·ªçng t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o.

Danh s√°ch b√°o c√°o c·∫ßn ph√¢n lo·∫°i (format [index]: text):
{input_list_text}
        """
        
        batch_classify_function = {
            "name": "batch_classify_bugs",
            "description": "Ph√¢n lo·∫°i nhi·ªÅu bug reports c√πng l√∫c",
            "parameters": {
                "type": "object",
                "properties": {
                    "classifications": {
                        "type": "array",
                        "description": "Danh s√°ch k·∫øt qu·∫£ ph√¢n lo·∫°i",
                        "items": {
                            "type": "object",
                            "properties": {
                                "index": {"type": "integer", "description": "Ch·ªâ s·ªë bug"},
                                "label": {
                                    "type": "string",
                                    "enum": labels,
                                },
                                "reason": {
                                    "type": "string",
                                    "description": "L√Ω do (< 30 t·ª´)",
                                },
                                "team": {
                                    "type": "string",
                                    "enum": team_groups,
                                },
                                "severity": {
                                    "type": "string",
                                    "enum": ["Low", "Medium", "High", "Critical"],
                                },
                            },
                            "required": ["index", "label", "reason"],
                        },
                    }
                },
                "required": ["classifications"],
            },
        }
        
        call_kwargs = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "You are a senior QA expert. Follow the structured prompt. Classify ALL bugs without omission. Output only valid JSON array.",
                },
                {"role": "user", "content": batch_prompt},
            ],
            "functions": [batch_classify_function],
            "function_call": {"name": "batch_classify_bugs"},
            "max_tokens": 4000,
        }
        if not self.model_name.startswith("gpt-5"):
            call_kwargs["temperature"] = 0.0
        
        response = await self._call_model_with_retries(
            call_kwargs, retries=4, backoff_factor=0.6
        )
        
        # Extract function call result
        message = response.choices[0].message
        parsed_array = None
        
        if message.function_call:
            try:
                args = json.loads(message.function_call.arguments)
                parsed_array = args.get("classifications", [])
            except Exception as e:
                logger.error(f"‚ùå Function call parse error: {e}")
        
        # Fallback: parse content as JSON array
        if not parsed_array and message.content:
            raw = message.content.strip()
            try:
                parsed_array = json.loads(raw)
                if not isinstance(parsed_array, list):
                    parsed_array = None
            except Exception:
                m = re.search(r"(\[\s*\{[\s\S]*\}\s*\])", raw)
                if m:
                    try:
                        parsed_array = json.loads(m.group(1))
                    except Exception:
                        parsed_array = None
        
        # Map results
        results = {}
        if parsed_array:
            logger.info(f"üìã Parsed {len(parsed_array)} results from GPT")
            for item in parsed_array:
                try:
                    idx = int(item.get("index"))
                    label = item.get("label")
                    reason = item.get("reason") or ""
                    team = item.get("team")
                    severity = item.get("severity")
                    
                    results[idx] = {
                        "label": label if label in labels else label,
                        "reason": reason.strip(),
                        "team": team,
                        "severity": severity,
                    }
                except Exception as e:
                    logger.error(f"‚ùå Error parsing item: {e}")
                    continue
        
        logger.info(f"‚úÖ Batch classification complete: {len(results)} results")
        logger.info("="*80 + "\n")
        return results


# Global instance (lazy loading)
_gpt_service = None

def get_gpt_service() -> GPTService:
    """Get singleton GPT service instance"""
    global _gpt_service
    if _gpt_service is None:
        _gpt_service = GPTService()
    return _gpt_service
